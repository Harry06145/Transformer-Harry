# This is a repository to create Transformer from nothing.

1. Embedding  √

2. MutiHeadAttention √

3. Encoder

敲到一半发现Layer Norm层没写，道心破碎了555

4. Decoder

5. Layer Norm √

6. CrossAttention

# This code will be replaced to MindSpore from Pytorch.

1. Embedding  

2. MutiHeadAttention 

3. Encoder

4. Decoder

5. Layer Norm 

6. CrossAttention
